{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e37455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations import ( \n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    GaussNoise, MotionBlur, MedianBlur, PiecewiseAffine,\n",
    "    Sharpen, Emboss, RandomBrightnessContrast, Flip, OneOf, Compose, RandomGamma, ElasticTransform, ChannelShuffle,RGBShift, Rotate,\n",
    "    Resize, RandomCrop, Rotate, HorizontalFlip\n",
    ")\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabe011",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentor():\n",
    "    return Compose([\n",
    "        Resize(512, 512),\n",
    "        Compose([\n",
    "            RandomRotate90(),\n",
    "            Flip(),\n",
    "            Transpose(),\n",
    "        ], p=0.15),        \n",
    "        OneOf([\n",
    "            Rotate(limit=[-60,60]),\n",
    "        ], p=0.5),\n",
    "        Compose([\n",
    "            ShiftScaleRotate()\n",
    "        ], p=0.05),\n",
    "        OneOf([\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=.1),\n",
    "            Blur(blur_limit=3, p=.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            PiecewiseAffine(p=0.2),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            Sharpen(),\n",
    "            Emboss(),\n",
    "            RandomBrightnessContrast()\n",
    "        ], p=0.3),\n",
    "        OneOf([\n",
    "            HueSaturationValue(p=0.3)\n",
    "        ], p=0.05),\n",
    "        Compose([\n",
    "            RandomCrop(500, 500),\n",
    "            Resize(512, 512)\n",
    "        ], p=0.05)\n",
    "    ], p=0.90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "logodir = 'logo_data'\n",
    "subdirs = os.walk(logodir)\n",
    "subdirs = [x[0] for x in subdirs]\n",
    "subdirs = subdirs[1:]\n",
    "print(subdirs)\n",
    "\n",
    "augoffset = 500\n",
    "augment = augmentor()\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa528324",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_path = 'logo_data_augments'\n",
    "for path in subdirs:\n",
    "    print(path, 'started')\n",
    "    images=[]\n",
    "    for filename in os.listdir(path):\n",
    "        imagepath = os.path.join(path,filename)\n",
    "        img = cv2.imread(imagepath)\n",
    "        if img is not None:\n",
    "            images.append(img) \n",
    "    logo_brand = path[10:]\n",
    "    branddir = os.path.join(extracted_path,logo_brand)\n",
    "    if not os.path.exists(branddir):\n",
    "        os.mkdir(branddir)\n",
    "    for i in range(augoffset):\n",
    "        imageindex = random.randint(0, len(images)-1)\n",
    "        img = images[imageindex]\n",
    "        augmented = augment(image=img)\n",
    "        augmentedimg = augmented['image']\n",
    "        newimgpath = os.path.join(branddir, logo_brand + str(i) + '.jpg')\n",
    "        out = cv2.imwrite(newimgpath, augmentedimg)\n",
    "    print(path, 'finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3034d7",
   "metadata": {},
   "source": [
    "#### Export LogoDet files as other_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f06342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export other_class type of logos&images for traning from LogoDet-3K dataset\n",
    "#Path to LogoDet-3K\n",
    "logodetpath = 'datasets/LogoDet-3K'\n",
    "dest_root = 'logo_data_augments/other_class'\n",
    "if not os.path.exists(dest_root):\n",
    "    os.makedirs(dest_root)\n",
    "for i, file in enumerate(glob.glob(os.path.join(logodetpath, '**/*.jpg'), recursive=True)):\n",
    "    if file.endswith(\".jpg\") and random.randint(1, 25) == 1:\n",
    "        destination = os.path.join(dest_root, str(i) + '.jpg')\n",
    "        print('Moved from: {} to {}'.format(file,destination) )\n",
    "        shutil.copyfile(file, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfb9b7",
   "metadata": {},
   "source": [
    "# Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_RATIO = 0.99\n",
    "data_dir = 'data/logo_data'\n",
    "\n",
    "images_dir = 'logo_data_augments'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "classes = os.listdir(images_dir)\n",
    "\n",
    "for label in tqdm(classes):\n",
    "    cls_label = str(label).replace(' ', '_')\n",
    "    class_dir = os.path.join(images_dir, label)\n",
    "\n",
    "    images = os.listdir(class_dir)\n",
    "\n",
    "    n_train = int(len(images) * TRAIN_VAL_RATIO)\n",
    "\n",
    "    train_images = images[:n_train]\n",
    "    test_images = images[n_train:]\n",
    "\n",
    "    os.makedirs(os.path.join(train_dir, cls_label), exist_ok = True)\n",
    "    os.makedirs(os.path.join(val_dir, cls_label), exist_ok = True)\n",
    "\n",
    "    for image in train_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(train_dir, cls_label, image.replace(' ', '_')) \n",
    "        shutil.copyfile(image_src, image_dst)\n",
    "\n",
    "    for image in test_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(val_dir, cls_label, image.replace(' ', '_')) \n",
    "        shutil.copyfile(image_src, image_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_dir = 'data/logo_data/val'\n",
    "train_data_dir = 'data/logo_data/train'\n",
    "\n",
    "os.makedirs('data/logo_data/meta', exist_ok = True)\n",
    "val_annotation_output = 'data/logo_data/meta/val.txt' \n",
    "train_annotation_output = 'data/logo_data/meta/train.txt' \n",
    "class_output = 'data/logo_data/meta/class_mapping.txt'\n",
    "counter = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(val_data_dir):\n",
    "  for dir_ in dirs:\n",
    "    class_name = str(dir_).replace(' ', '_')\n",
    "    folder_path = os.path.join(val_data_dir, class_name)\n",
    "\n",
    "    files = glob.glob(folder_path + '/**/*.png', recursive=True)\n",
    "    files_jpg = glob.glob(folder_path + '/**/*.jpg', recursive=True)\n",
    "    files.extend(files_jpg)\n",
    "\n",
    "    f=open(val_annotation_output,'a')\n",
    "    for file in files:\n",
    "        f.write(os.path.join(class_name,os.path.basename(file))+\" \"+str(counter)+'\\n')\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    f=open(class_output,'a')\n",
    "    f.write(class_name+\" \"+str(counter)+'\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "for subdir, dirs, files in os.walk(train_data_dir):\n",
    "  for dir_ in dirs:\n",
    "    class_name = str(dir_).replace(' ', '_')\n",
    "    folder_path = os.path.join(train_data_dir, class_name)\n",
    "\n",
    "    files = glob.glob(folder_path + '/**/*.png', recursive=True)\n",
    "    files_jpg = glob.glob(folder_path + '/**/*.jpg', recursive=True)\n",
    "    files.extend(files_jpg)\n",
    "    \n",
    "    f = open(class_output,'r')\n",
    "    text = f.read()\n",
    "    parsed_text = text.split()\n",
    "    indexOfDir = parsed_text.index(class_name)\n",
    "    label = parsed_text[indexOfDir+1]\n",
    "    f.close()\n",
    "    \n",
    "    f=open(train_annotation_output,'a')\n",
    "    for file in files:\n",
    "        f.write(os.path.join(class_name,os.path.basename(file))+\" \"+str(label)+'\\n')\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
